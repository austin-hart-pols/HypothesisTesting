---
title: "HYPOTHESIS TESTING"
subtitle: "4 tests in action"
author: "Austin Hart"
institute: "American University"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: [default, rladies, rladies-fonts]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
<<<<<<< HEAD
  message=FALSE, warning=FALSE, eval=TRUE, echo=FALSE, 
  fig.align = 'center', dev='svg'
=======
  message=FALSE, warning=FALSE, eval = TRUE, echo = FALSE, 
  fig.align = 'center', dev = 'svglite'
>>>>>>> 9d20796 (s23up)
)
```

```{r results='hide'}
library(tidyverse)
library(kableExtra)
library(janitor)

df = read_csv("hurricanes.csv") %>%
  filter(!is.na(femScale))

load('bechdel.Rdata')
mov = mov %>%
  mutate(Era = if_else(year %in% 1970:1990, "1970-1990","1991-2013"))
```

# Topics covered

- Hypothesis testing  
  
- Four implementations
  - $t$-test for sample means
  - $t$-test for difference of means
  - $t$-test for regression coefficients
  - $\chi^2$-test for tabular analysis
  
- Jung et al (2014). "Female-named hurricanes" 


---
class: inverse, middle, right

# HYPOTHESIS TESTING
### Logic and Process


---
# Hypothesis testing

### Statistical hypothesis testing 

> A method of inference that provides a basis for rejecting a hypothesis based on the plausibility of the data. 
>
> Typically for evaluating "statistical significance" of an association observed in sample data.


---
# Process for testing hypotheses

> Given a hypothesis about a population parameter, calculate the probability of finding your sample statistic.  
> Reject the hypothesis when probability is exceptionally low, typically below 0.05. 
  
Procedure:

- Specify hypotheses
  - Alternative: your expectation
  - Null: mutually-exclusive opposite
  
- Select appropriate test statistic (e.g., Z-score) 
  
- Specify decision rule for rejecting null  
  
- Compute test statistic  
  
- Conclude



---
# Select the right test statistic

> A test statistic is a number that standardizes your sample information in light of the null hypothesis.  
> It expresses the deviation of the sample mean from the hypothesized parameter as a number of standard errors.

<<<<<<< HEAD
- Pop parameters give shape to the sampling distribution

- Null an argument about parameters *AND, THEREFORE,* sampling dist

- Allows us to gauge probability of a sample stat


---
class: inverse, middle, right

# THE ALL MIGHTY p-VALUE
### Meaning and use

---
# The meaning of a p-value

> A p-value is the probability of observing a sample statistic under the assumption that the null hypothesis is true. 

- Start with your sample statistic, e.g. $\bar{Y}=65$

- Measure distance to the hypothesized parameter $\mu_0 \leq 50$

- Standardize wrt standard errors

$$ 
\begin{align}
t &= \frac{\bar{Y} - \mu_0}{\sigma_{\bar{Y}}} \\
&= \frac{65-50}{15} \\
&= 1
\end{align}
$$

- Calculate and connect  
=======
For a sample mean, you might compute the $Z$-statistic:
>>>>>>> 9d20796 (s23up)

$$
Z = \frac{\bar{y}-\mu_0}{s_y/\sqrt{n}}
$$



---
# To reject or not to reject?

### Set a decision rule for rejecting the null  


- Choose a level of significance, typically $\alpha = 0.05$  
  
- Find the critical value, $Z^*$  
   
- Reject null if test statistic larger than critical value


---
# Finding your critical value, 5% significance

.pull-left[
### Upper-tailed test

Null can only be wrong in one direction.

> Reject $H_0$ if $Z > 1.645$

```{r sclt1s, fig.width=3.5, fig.height=3, dpi=350}
  ggplot(NULL, aes(c(-3.5,3.5))) +
    geom_area(stat = "function", fun = dnorm, fill = "#00998a", xlim = c(-3, 1.645)) +
    geom_area(stat = "function", fun = dnorm, fill = "grey80", xlim = c(1.645, 3.5)) +
    labs(x = "Z", y = "") +
    scale_y_continuous(breaks = NULL,
                       expand = expansion(mult=c(0,0.05))) +
    scale_x_continuous(breaks = c(0,1.645)) +
    coord_cartesian(xlim = c(-3.5,3.5)) +
    theme_minimal() +
    theme(panel.grid.minor = element_blank())
```

]
.pull-right[
### Two-tailed test

Null can be wrong in either direction.

> Reject $H_0$ if $\lvert Z \rvert > 1.96$

```{r sclt2s, fig.width=3.5, fig.height=3, dpi=350}
  ggplot(NULL, aes(c(-3.5,3.5))) +
    geom_area(stat = "function", fun = dnorm, fill = "#00998a", xlim = c(-1.96, 1.96)) +
    geom_area(stat = "function", fun = dnorm, fill = "grey80", xlim = c(1.96, 3.5)) +
    geom_area(stat='function', fun = dnorm, fill = 'grey80', xlim = c(-3.5,-1.96)) +
    labs(x = "Z", y = "") +
    scale_y_continuous(breaks = NULL,
                       expand = expansion(mult=c(0,0.05))) +
    scale_x_continuous(breaks = c(-1.96,0,1.96)) +
    coord_cartesian(xlim = c(-3.5,3.5)) +
    theme_minimal() +
    theme(panel.grid.minor = element_blank())
```
]


---
class: inverse, middle, right

# FOUR TESTS IN R

### Using data from Jung et al. (2014)



---
class: inverse
# Population mean (t-test)

- I have data for ONE numeric variable.
<<<<<<< HEAD

- I want to test hypotheses about a pop mean
=======
- I want to test hypotheses about a pop mean. $\mu_y$
>>>>>>> 9d20796 (s23up)


---
# Population mean (t-test)

.left-column[
### Setup
]

.right-column[
<<<<<<< HEAD
> On balance, are hurricane names more feminine than masculine? Use student ratings (femScale) to find out.  

- State hypotheses

- Calculate $p$-value based on a $t$-test

=======
> On balance, hurricane names are more feminine than masculine. Use Jung et al's ratings to find out.

- State hypotheses
  
- Identify test statistic
  
- Set decision rule
  
- Calculate test statistic
  
>>>>>>> 9d20796 (s23up)
- Reject/fail to reject the null

]

---
# Population mean (t-test)

.left-column[
### Setup
### Hypotheses
]

.right-column[
<<<<<<< HEAD
> On balance, are hurricane names more feminine than masculine? Use student ratings (femScale) to find out.  

- $H_A:~\mu>5$

- $H_0:~\mu\leq5$

]

---
# Population mean (t-test)

.left-column[
### Setup
### Hypotheses
### t-test
]

.right-column[
> On balance, are hurricane names more feminine than masculine? Use student ratings (femScale) to find out.  


```{r tmean,echo=T}
t.test(df$femScale, mu = 5, alternative = 'greater')
=======
- $H_A:~\mu > 5$
  
- $H_0:~\mu\leq 5$

- Statistics from replication data:  

```{r tpoptab}
df %>%
  summarise(
    N = n(),
    Mean = mean(femScale),
    SD = sd(femScale) 
  ) %>%
  pivot_longer(cols = 1:3, names_to = 'Stat', values_to = 'Fem rating') %>%
  knitr::kable(digits = 1L, caption = 'Sample Statistics')
>>>>>>> 9d20796 (s23up)
```

]

---
# Population mean (t-test)

.left-column[
<<<<<<< HEAD
=======

>>>>>>> 9d20796 (s23up)
### Setup
### Hypotheses
### t-stats

]

.right-column[

- Appropriate test statistic: 

$$
t=\frac{\bar{y}-\mu_0}{s_y/\sqrt{n}}
$$
  
- Decision rule
  - 5% significance
  - One-sided test
  - Reject null if...
  
]

---
# Population mean (t-test)

.left-column[
### Setup
### Hypotheses
### t-stats
### Reject?
]

.right-column[
<<<<<<< HEAD
> On balance, are hurricane names more feminine than masculine? Use student ratings (femScale) to find out.  
=======
>>>>>>> 9d20796 (s23up)

- Calculate test statistic, $t$

- Reject or not?

<<<<<<< HEAD
=======
> I (reject/fail to reject) the null hypothesis. The mean score of 6.8 is (significantly/not significantly) ?? higher than 5 $(t=??,~p??)$, meaning that hurricane names are (significantly/not) more feminine on balance.

>>>>>>> 9d20796 (s23up)
]


---
class: inverse
# Difference of means (t-test)

- I have:
  - Numeric outcome variable
  - Binary exposure variable
  

- I want to know if the mean outcome differs by group


---
# Difference of means (t-test)

.left-column[
### Setup
]

.right-column[
<<<<<<< HEAD
> Are female-named hurricanes deadlier than male-named hurricanes? Describe the relationship, and evaluate the claim.

- State hypotheses

- Calculate $p$-value from diff of means test

- Reject/Fail to reject the null
=======
> Female-named hurricanes deadlier than male-named hurricanes. Describe the relationship, and evaluate the claim.

- State hypotheses
  
- Identify test statistic
  
- Set decision rule
  
- Calculate test statistic
  
- Reject/fail to reject the null
>>>>>>> 9d20796 (s23up)

]

---
# Difference of means (t-test)

.left-column[
### Setup
### Hypotheses
]

.right-column[
<<<<<<< HEAD
> Are female-named hurricanes deadlier than male-named hurricanes? Describe the relationship, and evaluate the claim.

- Alternative, $H_A:~\mu_{Fem} > \mu_{Male}$

- Null, $H_0~\mu_{Fem} \leq \mu_{Male}$

]

---
# Difference of means (t-test)

.left-column[
### Setup
### Hypotheses
### t-test
]

.right-column[
> Are female-named hurricanes deadlier than male-named hurricanes? Describe the relationship, and evaluate the claim.

```{r tmeans, echo=TRUE}
t.test(log(deaths+1) ~ gender, data = df,
       alternative = 'greater')
```

]

---
# Difference of means (t-test)

.left-column[
### Setup
### Hypotheses
### t-test
### Reject?
]

.right-column[
The table below shows the relationship between hurricane-name gender and deaths using data from 94 hurricanes that made landfall in the US from 1950 to 2012. Death totals ranged from a 0 to 1,833 (Katrina, 2005). Female-named hurricanes caused 57 deaths on average. Consistent with Jung et al.'s (2014) argument, male-named hurricanes saw an average of only 15 deaths. However, the difference of means is not statistically significant ($t = 0.92,~ p = 0.19$, 1-tailed test of log-transformed mean).

```{r ttest}

  df %>%
   group_by(gender) %>%
   summarise(
     N = n(),
     Min = min(deaths),
     Max = max(deaths),
     Med = median(deaths),
     Avg = mean(deaths),
     `Avg (log)` = mean(log(deaths+1))
   ) %>%
   kbl(digits = 1, caption = "Deaths by gendered name", type = 'html') %>%
   kable_paper(bootstrap_options = "striped", full_width = F, 
               position = "center")

```

]


---
class: inverse
# Equality of group means (F-test)

- I have:
  - Numeric outcome variable
  - Categorical exposure variable

- I want to know if the mean outcome differs across groups


---
# Comparing equality of group means (F-test)

> Evaluate the relationship between the intensity of the storm at landfall (category) and deaths caused. Use an F-test to assess the siginficance.

- State hypotheses, $H_0:$ equality of group means

- Calculate $p$-value based on $F$-test

- Reject/fail to reject the null


---
# Presenting results (F)

The table below summarizes the relationship between the category of storm at landfall and the loss of life. Category 1 storms are the most common and also the least deadly (mean = 13). [more on others] There are only three category 5 storms in the data with more than 700 deaths on average. The differences are statistically significant $(F = 31.14, ~ p < 0.001)$, and we reject the null hypothesis of independence.


```{r Ftest}
=======

- $H_A: ~ \mu_{Fem} - \mu_{Male} > 0$
  
- $H_0: ~ \mu_{Fem} - \mu_{Male} \leq 0$
  
- Summary stats from replication data:

```{r diffstats}
>>>>>>> 9d20796 (s23up)
df %>%
  group_by(gender) %>%
  summarise(
    n = n(),
    Mean = mean(deaths),
    SD = sd(deaths)
  ) %>%
  pivot_longer(2:4, names_to = ' ') %>% 
  pivot_wider(names_from = gender, values_from = value) %>%
  kable(digits = 1L, caption = 'Deaths by name')
  
```

]

---
# Difference of means (t-test)

.left-column[
### Setup
### Hypotheses
### t-stats
]

.right-column[

- Appropriate test statistic, difference of means

$$
t = \frac{(\bar{y_1}-\bar{y_2})-(\mu_1-\mu_2)}{\sqrt{s_1^2/n_1+s_2^2/n_2}}
$$

- Decision rule
  - For 5% significance
  - One-sided test
  - Reject null if...
]

---
# Difference of means (t-test)

.left-column[
### Setup
### Hypotheses
### t-stats
### Reject?
]

.right-column[


]


---
class: inverse

# Regression

- I have:
  - Numeric outcome variable
  - (typically) Numeric exposure variable


- I want to know if the mean outcome is related to level of exposure


---
# Testing regression coefficients

.left-column[

### Setup

]
<<<<<<< HEAD

=======
>>>>>>> 9d20796 (s23up)
.right-column[

> Hurricane damage is correlated with the "femininity" of the storm's name.

- State hypotheses
<<<<<<< HEAD

- Estimate the regression, eval the coefficient (t-test)

- Present the results
=======
  
- Identify test statistic
  
- Set decision rule
  
- Calculate test statistic
  
- Reject/fail to reject the null
>>>>>>> 9d20796 (s23up)

]

---
# Testing regression coefficients

.left-column[

### Setup
### Hypotheses

]
<<<<<<< HEAD

=======
>>>>>>> 9d20796 (s23up)
.right-column[

Given linear model: $damage_i = \beta_0 + \beta_1(femScale_i) + e_i$

<<<<<<< HEAD
Given PRF: $damage_i = \alpha + \beta(femScale_i) + e_i$
- $H_A:~\beta \neq 0$

- $H_0:~\beta = 0$

]

---
# Testing regression coefficients

.left-column[

### Setup
### Hypotheses
### Estimate

]

.right-column[

```{r ols1, echo=TRUE}
# Estimate and store
  e1 = lm(log(deaths + 1) ~ femScale, data = df)
  e2 = lm(log(damage) ~ femScale, data = df)

# Present as table
  stargazer(e1, e2, type = 'text', keep.stat = 'n')
=======
- $H_A:~ \beta_1 \neq 0$
  
- $H_0:~ \beta_1 = 0$

- Regression estimates from replication data:

```{r ols11}
# Estimate and store
  mfits = list(
    'Deaths' = lm(deaths ~ femScale, data = df),
    'Damage' = lm(damage ~ femScale, data = df)
  )
  cm = c('femScale' = 'Femininity of name',
         '(Intercept)' = 'Constant')
# Present as table
  modelsummary::modelsummary(mfits, fmt = 2, coef_map = cm,
                             title = "Storm 'femininity' and consequences",
                             gof_map = 'nobs', output = 'gt',
                             notes = 'Note: OLS ests with std errors in parentheses.')
  
>>>>>>> 9d20796 (s23up)
```

]

---
# Testing regression coefficients

.left-column[

### Setup
### Hypotheses
### t-stats

]
<<<<<<< HEAD
.right-column[
=======
>>>>>>> 9d20796 (s23up)

.right-column[

<<<<<<< HEAD
Note that this finding is robust to using damage as the outcome measure instead of deaths. Here we find mean damage increasing by about 3% with femininity, but the effect is not significantly different from 0 $(p=0.67)$. 

]
=======
> Hurricane damage is associated with the "femininity" of the storm's name.

- Appropriate test statistic, OLS regression 

$$
t=\frac{b_1 - \beta_1}{SE_b}
$$
  
- Decision rule
  - For 5% significance
  - TWO-sided test
  - Reject null if...
  
]

---
# Testing regression coefficients

.left-column[

### Setup
### Hypotheses
### t-stats
### Reject?

]
.right-column[

```{r ols12}
# Estimate and store
  mfits = list(
    'Deaths' = lm(deaths ~ femScale, data = df),
    'Damage' = lm(damage ~ femScale, data = df)
  )
  cm = c('femScale' = 'Femininity of name',
         '(Intercept)' = 'Constant')
# Present as table
  modelsummary::modelsummary(mfits, fmt = 2, coef_map = cm,
                             title = "Storm 'femininity' and consequences",
                             gof_map = 'nobs', output = 'gt',
                             notes = 'Note: OLS ests with std errors in parentheses.')
  
```

]

---
class: inverse

# Tabular analysis $(\chi^2)$

- I have:
  - Nominal outcome variable
  - Nominal exposure variable
  
- I want to know if the outcome and exposure variable are independent


---
# Tabular analysis

.left-column[
### Setup
]

.right-column[
> Development of female characters differs pre vs post 1990. Bechdel data.

- State hypotheses
  
- Identify test statistic
  
- Set decision rule
  
- Calculate test statistic
  
- Reject/fail to reject the null

]


---
# Tabular analysis

.left-column[
### Setup
### Hypotheses
]


.right-column[

- $H_0:$ Representation is independent of era
  
- $H_A:$ Representation differs by era

- Tabulation in sample:

```{r xtabs}
  xtab =
    mov %>% 
    count(BechdelBinary,Era) %>%  
    na.omit() %>%
    pivot_wider(
      names_from = Era,
      values_from = n, 
      values_fill = 0
    ) %>%
    mutate_if(
      is.integer, list(Percent = ~./sum(.) * 100)
    ) %>% 
    select(BechdelBinary,sort(tidyselect::peek_vars())) %>%
    adorn_totals()

  xtab %>%
    kbl(digits = 1, format = "html", 
        caption = "Bechdel over time", 
        col.names = c(" ","n","%","n","%")) %>%
    kable_paper(bootstrap_options = "striped", full_width = F, position = "center") %>%
    add_header_above(c(" " = 1,"1970-1990"=2,"1991-2013" = 2))
```

]
 
 
---
# Tabular analysis

.left-column[
### Setup
### Hypotheses
### chi-squared stats
]

.right-column[

- Appropriate test statistic

$$
\chi^2_{df} = \sum \frac{(O-E)^2}{E}
$$
  - $O=$ frequency in each cell
    
  - $E=\frac{row.total}{grand.total}*col.total$
    
  - $df=(x.cats-1)*(y.cats-1)$
  
- Decision rule
  - For 5% significance
  - Reject null if...
]
  
  
---
# Tabular analysis

.left-column[
### Setup
### Hypotheses
### chi-squared stats
]

.right-column[

Use data below to caluclate the $\chi^2$ test statistic.

```{r xtabs2}
  xtab =
    mov %>% 
    count(BechdelBinary,Era) %>%  
    na.omit() %>%
    pivot_wider(
      names_from = Era,
      values_from = n, 
      values_fill = 0
    ) %>% 
    select(BechdelBinary,sort(tidyselect::peek_vars())) %>%
    adorn_totals(where = c('row','col'))

  xtab %>%
    kbl(format = "html", 
        caption = "Bechdel over time") %>%
    kable_paper(bootstrap_options = "striped", full_width = F, position = "center")
```
]

---
# Tabular analysis

.left-column[
### Setup
### Hypotheses
### chi-squared stats
### Reject?
]

.right-column[

]
>>>>>>> 9d20796 (s23up)
